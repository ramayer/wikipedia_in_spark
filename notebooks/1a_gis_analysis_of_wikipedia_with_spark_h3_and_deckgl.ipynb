{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "reasonable-texture",
   "metadata": {},
   "source": [
    "# GIS visualization of Wikipedia\n",
    "## TL/DR:\n",
    "\n",
    "1. Start with a Wikipedia Dump, preprocessed into Spark by the notebook 0_spark_preprocessing_of_wikipedia.ipynb\n",
    "2. Produce interactive maps similar to this screenshot: ![alt text](all_wikipedia_coords.png \"Title\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-calculator",
   "metadata": {},
   "source": [
    "## Install dependencies\n",
    "\n",
    "This is using `%pip` rather than `pkg_resources.resolve()` because on this environment's spark cluster, `%pip` will make sure the libraries are available on the spark worker nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "statistical-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_packages = {\"mwparserfromhell\",\"geopandas\",\"h3\",\"geocoder\",\"pydeck\"}\n",
    "import pkg_resources\n",
    "for lib in required_packages - {pkg.key for pkg in pkg_resources.working_set}:\n",
    "    print(f\"installing {lib}\")\n",
    "    %pip install -q --upgrade pip\n",
    "    %pip install -q $lib\n",
    "    pkg_resources.require(lib)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-thesaurus",
   "metadata": {},
   "source": [
    "### Set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_file_directory= '.'\n",
    "if sys.env.contains(\"DATABRICKS_RUNTIME_VERSION\"):\n",
    "    static_file_directory = '/dbfs/FileStore/wikipedia'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "revolutionary-penguin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.sax\n",
    "import json\n",
    "import mwparserfromhell\n",
    "import subprocess\n",
    "import json\n",
    "import time\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-motor",
   "metadata": {},
   "source": [
    "## Launch Spark (if running on a standalone environment)\n",
    "\n",
    "* On databricks clusters the Spark Context will already have existed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "identical-melissa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://08651cc65d10:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MyApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd9080069d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not \"spark\" in locals():\n",
    "    import pyspark\n",
    "    MAX_MEMORY = \"8g\"  # 24 gives OOM here. # 6 gives \"out of heap space\"\n",
    "    spark = (pyspark.sql.SparkSession.builder.appName(\"MyApp\") \n",
    "        .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:0.8.0\") \n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \n",
    "        .config(\"spark.executor.memory\", MAX_MEMORY) \n",
    "        .config(\"spark.driver.memory\", MAX_MEMORY) \n",
    "        .config(\"spark.python.worker.reuse\",False)\n",
    "        .config(\"spark.task.maxFailures\",5)\n",
    "        .enableHiveSupport() \n",
    "        .getOrCreate()        \n",
    "        )\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "relevant-luther",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_h3</th>\n",
       "      <th>num_h4</th>\n",
       "      <th>num_h5</th>\n",
       "      <th>num_h6</th>\n",
       "      <th>num_h7</th>\n",
       "      <th>num_h8</th>\n",
       "      <th>num_h9</th>\n",
       "      <th>count(1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21799</td>\n",
       "      <td>72608</td>\n",
       "      <td>206136</td>\n",
       "      <td>498461</td>\n",
       "      <td>883727</td>\n",
       "      <td>1164699</td>\n",
       "      <td>1335738</td>\n",
       "      <td>1855143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_h3  num_h4  num_h5  num_h6  num_h7   num_h8   num_h9  count(1)\n",
       "0   21799   72608  206136  498461  883727  1164699  1335738   1855143"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# About a half million h6 grids with information in wikipedia.\n",
    "spark.sql('''\n",
    "  select count(distinct coord.h3[3]) as num_h3,\n",
    "         count(distinct coord.h3[4]) as num_h4,\n",
    "         count(distinct coord.h3[5]) as num_h5,\n",
    "         count(distinct coord.h3[6]) as num_h6,\n",
    "         count(distinct coord.h3[7]) as num_h7,\n",
    "         count(distinct coord.h3[8]) as num_h8,\n",
    "         count(distinct coord.h3[9]) as num_h9,\n",
    "         count(*)\n",
    " from wikipedia_silver_structured_templates\n",
    " lateral view explode(coords) as coord\n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "attended-contest",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_kepler_gl = False \n",
    "# kepler_gl doesn't play well in Jupyter Lab or Databricks notebooks.\n",
    "# Embedding it in an iframe seems to kinda help - but many features are still broken\n",
    "if try_kepler_gl:\n",
    "    h3s = spark.sql('''\n",
    "     select coord.h3[2] as h3,\n",
    "            count(*) as num_pages,\n",
    "            log(count(*)) as log_num_pages,\n",
    "            array_join(array_distinct(array(first(title),last(title))),' ... ') as example_pages\n",
    "     from wikipedia_silver_structured_templates\n",
    "     lateral view explode(coords) as coord\n",
    "     where size(coords)>0\n",
    "     group by coord.h3[2]\n",
    "     order by num_pages desc\n",
    "    ''').limit(100000).toPandas()\n",
    "    import keplergl\n",
    "    map_1 = keplergl.KeplerGl(height=600) # ,config=kepler_config)\n",
    "    #map_1.add_data(data=pdf,name='points')\n",
    "    map_1.add_data(data=h3s,name='h3s')\n",
    "    keplergl_html = str(map_1._repr_html_(),'utf-8')\n",
    "    # Firefox will only display the keplergl element \n",
    "    # if the HTML is embedded into an iframe's source as base64.\n",
    "    import base64\n",
    "    b64 = base64.b64encode(keplergl_html.encode('utf-8'))\n",
    "    src = f\"data:text/html;base64,{b64.decode('utf-8')}\"\n",
    "    html = f'<iframe src=\"{src}\" style=\"width:100%; height: 600px\">'\n",
    "    from IPython.core.display import HTML\n",
    "    result = HTML(html)\n",
    "try_kepler_gl and result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fourth-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'iframe' or 'inline' or 'none'\n",
    "#\n",
    "# Displaying the maps inline is convenient for debugging but makes the notebook painfully large for git.\n",
    "# (rerun with this set to 'iframe' before checking in)\n",
    "#\n",
    "display_mode = 'iframe'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "protective-weather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_log_n = Row(count=206136, max_log_n=8.71308886823731, p25=0.0, p50=0.6931471805599453, p95=3.332204510175204, p98=3.9889840465642745, p99=4.574710978503383)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"wikipedia_map_at_h3_5.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd8c2e0d910>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "render_in_deckgl = True\n",
    "h3_lvl = 5\n",
    "if render_in_deckgl:\n",
    "    import pydeck\n",
    "    h3s = spark.sql(f'''\n",
    "     select coord.h3[{h3_lvl}] as h3,\n",
    "            array_min(array(count(*),255)) as num_pages,\n",
    "            log(count(*)) as log_n,\n",
    "            first(coord.lat) as lat,\n",
    "            first(coord.lon) as lng,\n",
    "            array_join(array_distinct(array(first(title),last(title))),' ... ') as example_pages\n",
    "     from wikipedia_silver_structured_templates\n",
    "     lateral view explode(coords) as coord\n",
    "     where size(coords)>0\n",
    "     group by coord.h3[{h3_lvl}]\n",
    "     order by num_pages desc\n",
    "    ''').limit(500000).cache() # 800,000 crashes the browser on my laptop.\n",
    "\n",
    "    log_n_stats = h3s.selectExpr('count(*) as count',\n",
    "                                 'max(log_n) as max_log_n',\n",
    "                                 'approx_percentile(log_n, 0.25, 100) as p25',\n",
    "                                 'approx_percentile(log_n, 0.50, 100) as p50',\n",
    "                                 'approx_percentile(log_n, 0.95, 100) as p95',\n",
    "                                 'approx_percentile(log_n, 0.98, 200) as p98',\n",
    "                                 'approx_percentile(log_n, 0.99, 500) as p99'\n",
    "                               ).collect()[0]\n",
    "    print(f'max_log_n = {log_n_stats}')\n",
    "\n",
    "    # make everything above the 99% percentile white ()\n",
    "    max_log_n = log_n_stats['p99']\n",
    "    layer = pydeck.Layer(\n",
    "        'H3HexagonLayer',\n",
    "        h3s.toPandas(),\n",
    "        get_hexagon = 'h3',\n",
    "        auto_highlight = True,\n",
    "        stroked=False,\n",
    "        # ramp up red for the first 25%\n",
    "        # ramp up yellow for the middle 50%\n",
    "        # ramp up white for the final 25%\n",
    "        get_fill_color = f'[(log_n < {max_log_n}/4) ? 128 + log_n/{max_log_n}*4*256/2 : 255,'\n",
    "                         f' (log_n < {max_log_n}/4) ? 0 : (log_n > 3*{max_log_n}/4) ? 255 : (log_n/{max_log_n} - 0.25)*255*2'\n",
    "                         f' log_n > {max_log_n}*3/4 ? (log_n/{max_log_n} - 0.75)*4*255 : 0,'\n",
    "                         f' 256]',\n",
    "        get_line_color=[0, 255, 255],\n",
    "        #elevation_scale=50,\n",
    "        #elevation_range=[0, 3000],\n",
    "        #extruded=True,  \n",
    "        extruded=False,\n",
    "        pickable=True,\n",
    "        coverage=1)\n",
    "\n",
    "    view_state = pydeck.ViewState(\n",
    "        longitude=-1.415,\n",
    "        latitude=52.2323,\n",
    "        zoom=3,\n",
    "        min_zoom=0,\n",
    "        max_zoom=15,\n",
    "        pitch=0,\n",
    "        bearing=0)\n",
    "\n",
    "    r = pydeck.Deck(layers=[layer], initial_view_state=view_state)\n",
    "    result = r.to_html(f'wikipedia_map_at_h3_{h3_lvl}.html',iframe_height=600)\n",
    "\n",
    "(display_mode == 'inline') and result or IPython.display.IFrame(f'wikipedia_map_at_h3_{h3_lvl}.html',800,600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "failing-florist",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_log_n = Row(count=498461, max_log_n=7.984121958702927, p25=0.0, p50=0.6931471805599453, p95=2.3978952727983707, p98=3.044522437723423, p99=3.4011973816621555)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"globe_view.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd9053799a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydeck as pdk\n",
    "import pandas as pd\n",
    "import pydeck\n",
    "render_globe_view=True\n",
    "if render_globe_view:\n",
    "    lvl=6\n",
    "    h3s = spark.sql(f'''\n",
    "     select coord.h3[{lvl}] as h3,\n",
    "            count(*) as num_pages,\n",
    "            log(count(*)) as log_n,\n",
    "            first(coord.lat) as lat,\n",
    "            first(coord.lon) as lng,\n",
    "            array_join(array_distinct(array(first(title),last(title))),' ... ') as example_pages\n",
    "     from wikipedia_silver_structured_templates\n",
    "     lateral view explode(coords) as coord\n",
    "     where size(coords)>0\n",
    "     group by coord.h3[{lvl}]\n",
    "     order by num_pages desc\n",
    "    ''').limit(500000).cache() # 800,000 crashes the browser on my laptop.\n",
    "\n",
    "    log_n_stats = h3s.selectExpr('count(*) as count',\n",
    "                                 'max(log_n) as max_log_n',\n",
    "                                 'approx_percentile(log_n, 0.25, 100) as p25',\n",
    "                                 'approx_percentile(log_n, 0.50, 100) as p50',\n",
    "                                 'approx_percentile(log_n, 0.95, 100) as p95',\n",
    "                                 'approx_percentile(log_n, 0.98, 200) as p98',\n",
    "                                 'approx_percentile(log_n, 0.99, 500) as p99'\n",
    "                               ).collect()[0]\n",
    "    print(f'max_log_n = {log_n_stats}')\n",
    "\n",
    "    # make everything above the 99% percentile white ()\n",
    "    max_log_n = log_n_stats['p99']\n",
    "\n",
    "    COUNTRIES = \"https://d2ad6b4ur7yvpq.cloudfront.net/naturalearth-3.3.0/ne_50m_admin_0_scale_rank.geojson\"\n",
    "\n",
    "    view_state = pdk.ViewState(latitude=0, longitude=0, zoom=2,         min_zoom=0,\n",
    "            max_zoom=15)\n",
    "\n",
    "    # Set height and width variables\n",
    "    view = pdk.View(type=\"_GlobeView\", controller=True, width=1000, height=700)\n",
    "\n",
    "    layers = [\n",
    "        pdk.Layer(\n",
    "            \"GeoJsonLayer\",\n",
    "            id=\"base-map\",\n",
    "            data=COUNTRIES,\n",
    "            stroked=False,\n",
    "            filled=True,\n",
    "            get_fill_color=[30,50,30],\n",
    "        ),\n",
    "        pydeck.Layer(\n",
    "                'H3HexagonLayer',\n",
    "                h3s.toPandas(),\n",
    "                get_hexagon = 'h3',\n",
    "                auto_highlight = True,\n",
    "                # ramp up red for the first 25%\n",
    "                # ramp up yellow for the middle 50%\n",
    "                # ramp up white for the final 25%\n",
    "                get_fill_color = f'[(log_n < {max_log_n}/4) ? 128 + log_n/{max_log_n}*4*256/2 : 255,'\n",
    "                                 f' (log_n < {max_log_n}/4) ? 0 : (log_n > 3*{max_log_n}/4) ? 255 : (log_n/{max_log_n} - 0.25)*255*2'\n",
    "                                 f' log_n > {max_log_n}*3/4 ? (log_n/{max_log_n} - 0.75)*4*255 : 0,'\n",
    "                                 f' 256]',\n",
    "                get_elevation='log_n',\n",
    "                # radius=11000,\n",
    "                elevation_scale=50000,\n",
    "                elevation_range=[1,200000],\n",
    "                extruded=False,#True,  \n",
    "                pickable=True,\n",
    "                coverage=1)\n",
    "    ]\n",
    "    #layers = layers[:1]\n",
    "    deck = pdk.Deck(\n",
    "        views=[view],\n",
    "        initial_view_state=view_state,\n",
    "        #tooltip={\"text\": \"{name}, {primary_fuel} plant, {country}\"},\n",
    "        layers=layers,\n",
    "        # Note that this must be set for the globe to be opaque\n",
    "        parameters={\"cull\": True},\n",
    "    )\n",
    "\n",
    "    result = deck.to_html(\"globe_view.html\", css_background_color=\"black\",iframe_height=600)\n",
    "    \n",
    "(display_mode == 'inline') and result or IPython.display.IFrame('globe_view.html',800,600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "breathing-cream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"scatterplot.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd9a4427040>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Working blendfunc\n",
    "#    https://deck.gl/docs/api-reference/json/conversion-reference\n",
    "\n",
    "import pydeck\n",
    "import pydeck as pdk\n",
    "\n",
    "render_scatterplot = True\n",
    "if render_scatterplot:\n",
    "\n",
    "    dfpts = spark.sql('''\n",
    "      select coord.lon as lng, coord.lat as lat,title from wikipedia_silver_structured_templates \n",
    "      lateral view explode(coords) as coord \n",
    "      limit 1000000\n",
    "      ''')  # 2,000,000 crashes firefox on a moderate desktop\n",
    "\n",
    "    pdfpts = dfpts.toPandas()\n",
    "    layer = pdk.Layer(\n",
    "        \"ScatterplotLayer\",\n",
    "        pdfpts,\n",
    "        pickable=True,\n",
    "        opacity=1,\n",
    "        stroked=False,\n",
    "        filled=True,\n",
    "        radius_scale=10000,\n",
    "        radius_min_pixels=1,\n",
    "        radius_max_pixels=20,\n",
    "        line_width_min_pixels=1,\n",
    "        get_position=['lng', 'lat'],\n",
    "        #get_position=\"coordinates\",\n",
    "        get_radius=\"exits_radius\",\n",
    "        get_fill_color=[196, 16, 4],\n",
    "        get_line_color=[0, 0, 0],\n",
    "        parameters= {\n",
    "            'blend': True,\n",
    "            'depthTest': False,\n",
    "            'blendFunc': [770, 772]   # pydeck makes it really hard to find these enums.  \n",
    "          }\n",
    "    )\n",
    "\n",
    "    # Set the viewport location\n",
    "    view_state = pdk.ViewState(\n",
    "        longitude=-0.2,\n",
    "        latitude=51.5,\n",
    "        zoom=3,\n",
    "        min_zoom=0,\n",
    "        max_zoom=18,\n",
    "        pitch=0,\n",
    "        bearing=0)\n",
    "\n",
    "    # Combined all of it and render a viewport\n",
    "\n",
    "    r = pdk.Deck(layers=[layer], initial_view_state=view_state)\n",
    "    dir(r)\n",
    "    r.to_html('scatterplot.html')\n",
    "    import json\n",
    "    #print(json.dumps(json.loads(r.to_json()),indent=1))\n",
    "    #r.to_html('hexagon-example.html')\n",
    "    #### https://deck.gl/docs/api-reference/json/conversion-reference --- does that show how the javascript should look?\n",
    "    \n",
    "    \n",
    "#render_scatterplot and r\n",
    "(display_mode == 'inline') and r or IPython.display.IFrame('scatterplot.html',800,600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "opponent-girlfriend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"600\"\n",
       "            src=\"scatterplot_globe.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd9a44547c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydeck as pdk\n",
    "import pandas as pd\n",
    "import pydeck\n",
    "lvl=5\n",
    "\n",
    "render_scatterplot_on_globe = True\n",
    "if render_scatterplot_on_globe:\n",
    "\n",
    "\n",
    "    COUNTRIES = \"https://d2ad6b4ur7yvpq.cloudfront.net/naturalearth-3.3.0/ne_50m_admin_0_scale_rank.geojson\"\n",
    "\n",
    "    view_state = pdk.ViewState(latitude=0, longitude=0, zoom=2,         min_zoom=0,\n",
    "            max_zoom=15)\n",
    "\n",
    "    # Set height and width variables\n",
    "    view = pdk.View(type=\"_GlobeView\", controller=True, width=1000, height=700)\n",
    "\n",
    "    dfpts = spark.sql('''\n",
    "      select coord.lon as lng, coord.lat as lat,title from wikipedia_silver_structured_templates \n",
    "      lateral view explode(coords) as coord \n",
    "      limit 1000000\n",
    "      ''')  # 2,000,000 crashes firefox on a moderate desktop\n",
    "\n",
    "    pdfpts = dfpts.toPandas()\n",
    "    layer = pdk.Layer(\n",
    "        \"ScatterplotLayer\",\n",
    "        pdfpts,\n",
    "        pickable=True,\n",
    "        opacity=1,\n",
    "        stroked=False,\n",
    "        filled=True,\n",
    "        radius_scale=10000,\n",
    "        radius_min_pixels=1,\n",
    "        radius_max_pixels=15,\n",
    "        line_width_min_pixels=1,\n",
    "        get_position=['lng', 'lat'],\n",
    "        #get_position=\"coordinates\",\n",
    "        get_radius=\"exits_radius\",\n",
    "        #get_fill_color=[196, 16, 4],\n",
    "        get_fill_color=[196, 16, 4],\n",
    "        #get_fill_color=[16, 4, 196],\n",
    "        get_line_color=[0, 0, 0],\n",
    "        parameters= {\n",
    "            'blend': True,\n",
    "            'depthTest': False,\n",
    "            'blendFunc': [770, 772]   # pydeck makes it really hard to find these enums.  \n",
    "          }\n",
    "    )\n",
    "    layers = [\n",
    "        pdk.Layer(\n",
    "            \"GeoJsonLayer\",\n",
    "            id=\"base-map\",\n",
    "            data=COUNTRIES,\n",
    "            stroked=False,\n",
    "            filled=True,\n",
    "            get_fill_color=[30,40,30],\n",
    "        ),\n",
    "        layer\n",
    "    ]\n",
    "    #layers = layers[:1]\n",
    "    deck = pdk.Deck(\n",
    "        views=[view],\n",
    "        initial_view_state=view_state,\n",
    "        #tooltip={\"text\": \"{name}, {primary_fuel} plant, {country}\"},\n",
    "        layers=layers,\n",
    "        # Note that this must be set for the globe to be opaque\n",
    "        parameters={\"cull\": True},\n",
    "    )\n",
    "    deck.to_html(\"scatterplot_globe.html\", css_background_color=\"black\",iframe_height=600)\n",
    "    \n",
    "(display_mode == 'inline') and r or IPython.display.IFrame('scatterplot_globe.html',1000,600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-action",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "* http://mcburton.net/blog/static-files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sufficient-volleyball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+---------------------------------------------+\n",
      "|title                        |body                                         |\n",
      "+-----------------------------+---------------------------------------------+\n",
      "|Black panther                |{{short description|Melanistic colour va...  |\n",
      "|Great white shark            |{{other uses of|great white|Great White ...  |\n",
      "|Melisende, Queen of Jerusalem|{{short description|Queen regnant of the...  |\n",
      "|Carcharodon carcharias       |#REDIRECT [[Great white shark]] \\n \\n {{Re...|\n",
      "|Method                       |{{Wiktionary|method}} \\n '''Method''' ({{... |\n",
      "+-----------------------------+---------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(r\"select title,replace(substr(body,1,40)||'...','\\n','\\\\n') as body from wikipedia_bronze limit 5\").show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "occupied-istanbul",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='demo.html' target='_blank'>demo.html</a><br>"
      ],
      "text/plain": [
       "/home/jovyan/work/wikipedia_in_spark/notebooks/demo.html"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink, FileLinks\n",
    "FileLink('demo.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "smoking-performance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on FileLink in module IPython.lib.display object:\n",
      "\n",
      "class FileLink(builtins.object)\n",
      " |  FileLink(path, url_prefix='', result_html_prefix='', result_html_suffix='<br>')\n",
      " |  \n",
      " |  Class for embedding a local file link in an IPython session, based on path\n",
      " |  \n",
      " |  e.g. to embed a link that was generated in the IPython notebook as my/data.txt\n",
      " |  \n",
      " |  you would do::\n",
      " |  \n",
      " |      local_file = FileLink(\"my/data.txt\")\n",
      " |      display(local_file)\n",
      " |  \n",
      " |  or in the HTML notebook, just::\n",
      " |  \n",
      " |      FileLink(\"my/data.txt\")\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, path, url_prefix='', result_html_prefix='', result_html_suffix='<br>')\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str\n",
      " |          path to the file or directory that should be formatted\n",
      " |      url_prefix : str\n",
      " |          prefix to be prepended to all files to form a working link [default:\n",
      " |          '']\n",
      " |      result_html_prefix : str\n",
      " |          text to append to beginning to link [default: '']\n",
      " |      result_html_suffix : str\n",
      " |          text to append at the end of link [default: '<br>']\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      return absolute path to file\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  html_link_str = \"<a href='%s' target='_blank'>%s</a>\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(FileLink('demo.html'))\n",
    "#FileLink('demo.html').html_link_str\n",
    "#FileLink('demo.html').path\n",
    "#FileLink('demo.html').result_html_prefix\n",
    "#FileLink('demo.html').result_html_suffix\n",
    "#FileLink('demo.html').url_prefix\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
